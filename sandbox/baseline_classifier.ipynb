{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "from typing import List, Callable\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#from rulefit import RuleFit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, TunedThresholdClassifierCV\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "#from category_encoders import JamesSteinEncoder, CatBoostEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# add ../src to python path\n",
    "sys.path.insert(0, os.path.join(os.path.abspath('.'),'..', 'src'))\n",
    "\n",
    "import tree_utils"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Try from sklego.meta import HierarchicalClassifier\n",
    "# hc = HierarchicalClassifier(\n",
    "#    estimator=LogisticRegression(),\n",
    "#    groups=groups\n",
    "#).fit(X, y)\n",
    "#hc.estimators_"
   ],
   "id": "2da11eab31e03653",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_path =  r\"J:\\Onderzoek\\21-763_rvanes_MiniECG-2-Data\\E_ResearchData\\2_ResearchData\\Analysis\"\n",
    "file_name =  r\"input_decision_tree_complete.pkl\"\n",
    "\n",
    "num_splits = 10\n",
    "num_repeats = 10\n",
    "USE_CLASS_WEIGHT = True\n",
    "ALL_FEATURES = True\n",
    "USE_REDUCED_LABELS = True\n",
    "ALL_FEATURES_STRING = \"_useAllvars\" if ALL_FEATURES else \"\"\n",
    "CLASS_WEIGHT_STRING = \"_withClassWeights\" if USE_CLASS_WEIGHT else \"\"\n",
    "REDUCED_LABEL_STRING = \"_withReducedLabels\" if USE_REDUCED_LABELS else \"\""
   ],
   "id": "b287448247b39c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(os.path.join(data_path, file_name), 'rb') as f:\n",
    "    input_decision_tree_complete = pickle.load(f)"
   ],
   "id": "4c8568e7c45a3b69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "DATA = pd.DataFrame(input_decision_tree_complete).T",
   "id": "6d358b6d09bb7abf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "morphology_columns = [c for c in DATA.columns if 'morphology' in c]\n",
    "for c in morphology_columns:\n",
    "    DATA.loc[:, c] = DATA[c].apply(lambda x: x[0].strip(\",\").strip(\" \"))\n",
    "    DATA.loc[:, c] = DATA[c].apply(lambda x: x if x.strip()!=\"\" else \"none\")"
   ],
   "id": "140fe6b8f4ccc11c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "morphology_values = []\n",
    "for c in morphology_columns:\n",
    "    morphology_values.extend(DATA[c].unique().tolist())\n",
    "morphology_values = list(set(morphology_values))"
   ],
   "id": "eda403d789cb7adb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model prepping",
   "id": "b22bea538597a99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: need to add a feature combiner, perhaps use PySR or GpLearn\n",
    "\n",
    "impute_kwargs = {\n",
    "    'estimator': LinearRegression(), \n",
    "    'random_state':7,\n",
    "    'imputation_order': 'ascending', \n",
    "    'skip_complete': False,\n",
    "    'max_iter': 250,\n",
    "    'initial_strategy': 'median',\n",
    "    'add_indicator': True\n",
    "}\n",
    "gradientboosting_kwargs = {\n",
    "    'n_estimators': 500, \n",
    "    'max_depth': 10, \n",
    "    'learning_rate':0.01,\n",
    "    'max_leaf_nodes':40,\n",
    "    'random_state': 7\n",
    "}\n",
    "randomforest_kwargs = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 2, \n",
    "    'min_samples_leaf': 1,\n",
    "    'random_state': 7\n",
    "}\n",
    "rulefit_kwargs={\n",
    "    'tree_size': 10,\n",
    "    'max_rules': 100,\n",
    "    'tree_generator': GradientBoostingClassifier(**gradientboosting_kwargs)\n",
    "}\n",
    "decisiontree_kwargs = {\n",
    "    'criterion':'gini', \n",
    "    'splitter':'best', \n",
    "    'max_depth':10, \n",
    "    'min_samples_split':10, \n",
    "    'min_samples_leaf': 5, \n",
    "    'min_weight_fraction_leaf':0.0, \n",
    "    'max_features':None, \n",
    "    'random_state':7, \n",
    "    'max_leaf_nodes':50,\n",
    "    'class_weight': 'balanced'\n",
    "}\n",
    "xgboost_kwargs = {\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 6,\n",
    "    'max_leaves': 50,\n",
    "    'learning_rate': 1e-3,\n",
    "    'gamma': 0.4,\n",
    "    'subsample': 0.55,\n",
    "    'colsample_bytree':0.85,\n",
    "    'reg_alpha': 0.005\n",
    "    }"
   ],
   "id": "6004219c54779520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Axis model",
   "id": "5af910b8b1a3657e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target_col = \"Heart Axis Diagnosis\"\n",
    "target_inclusion = ['Left', 'Normal', 'Right', 'Extreme']\n",
    "Reduction_map = {'Left': 'Disease', \n",
    "                 'Right': 'Disease',\n",
    "                 'Extreme': 'Disease',\n",
    "                 'Normal': 'Normal'}\n",
    "if ALL_FEATURES:\n",
    "    features_to_use = []\n",
    "else:\n",
    "    features_to_use = ['qrs_vector mean lead_0',\n",
    "                     'p_vector mean lead_0',\n",
    "                     't_vector mean lead_0',\n",
    "                     'qrs_vector mean lead_1',\n",
    "                     'p_vector mean lead_1',\n",
    "                     't_vector mean lead_1',\n",
    "                     'qrs_vector mean lead_2',\n",
    "                     'p_vector mean lead_2',\n",
    "                     't_vector mean lead_2',\n",
    "                     'qrs_vector mean lead_3',\n",
    "                     'p_vector mean lead_3',\n",
    "                     't_vector mean lead_3',\n",
    "                     'qrs_vector mean lead_4',\n",
    "                     'p_vector mean lead_4',\n",
    "                     't_vector mean lead_4',\n",
    "                     'qrs_vector mean lead_5',\n",
    "                     'p_vector mean lead_5',\n",
    "                     't_vector mean lead_5',\n",
    "                     'qrs_vector mean lead_6',\n",
    "                     'p_vector mean lead_6',\n",
    "                     't_vector mean lead_6',\n",
    "                     'qrs_vector mean lead_7',\n",
    "                     'p_vector mean lead_7',\n",
    "                     't_vector mean lead_7'\n",
    "                       ]"
   ],
   "id": "2b0a8c5759074ef9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if len(features_to_use)==0:\n",
    "    meas_cols = [c for c in DATA.columns if ('Dataset' not in c) \n",
    "                 & (target_col not in c)\n",
    "                 & ('Diagnosis' not in c)]\n",
    "else:\n",
    "    meas_cols = features_to_use\n",
    "    \n",
    "fstring = f\"AXIS_{CLASS_WEIGHT_STRING}{ALL_FEATURES_STRING}{REDUCED_LABEL_STRING}\"\n",
    "os.makedirs(os.path.join(data_path, fstring), exist_ok=True)\n",
    "\n",
    "AXIS_DATA = DATA.loc[DATA[target_col].isin(target_inclusion), meas_cols+[target_col]+['Dataset']]\n",
    "if USE_REDUCED_LABELS:\n",
    "    AXIS_DATA.loc[:, target_col] = AXIS_DATA[target_col].map(Reduction_map)\n",
    "    \n",
    "AXIS_DATA.to_parquet(os.path.join(data_path, fstring, 'DATA.parquet'))\n",
    "AXIS_DATA = AXIS_DATA.drop('Dataset', axis=1)"
   ],
   "id": "aea10a2f941fc161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TRAINING LOOP",
   "id": "f8b76eb1c95fd94d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "OrdEncoder = OrdinalEncoder(\n",
    "    categories='auto',\n",
    "    dtype=int,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-2,\n",
    "    encoded_missing_value=-1,\n",
    ")\n",
    "PipeOrdEncoder = ColumnTransformer([(\"cat_encoder\", OrdEncoder, morphology_columns)], remainder='passthrough')\n",
    "#\n",
    "if ALL_FEATURES:\n",
    "    _cat_enc = PipeOrdEncoder\n",
    "else:\n",
    "    _cat_enc = None\n",
    "    \n",
    "le_pipe_rf = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"RandomForest\", RandomForestClassifier(**randomforest_kwargs))])\n",
    "\n",
    "le_pipe_gbc = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"GradientBoosting\", GradientBoostingClassifier(**gradientboosting_kwargs))])\n",
    "\n",
    "le_pipe_xgb = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"XGBoost\", XGBClassifier(**xgboost_kwargs))])\n",
    "\n",
    "le_pipe_dt = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"DecisionTree\", DecisionTreeClassifier(**decisiontree_kwargs))])\n",
    "\n",
    "PipeDict = {\n",
    "    'rf': le_pipe_rf,\n",
    "    'gbc': le_pipe_gbc,\n",
    "    'xgb': le_pipe_xgb,\n",
    "    'dt': le_pipe_dt    \n",
    "}"
   ],
   "id": "2cbc15f32235d91b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits=num_splits, n_repeats=num_repeats, random_state=7)\n",
    "\n",
    "X = AXIS_DATA.iloc[:, :-1]\n",
    "Y = AXIS_DATA.iloc[:,-1]\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lbe = LabelEncoder()\n",
    "\n",
    " #(RES_LIST_AXIS[0]['Y_test'])\n",
    "Yenc = lbe.fit_transform(Y.values) #(RES_LIST_AXIS[0]['Y_test'])\n",
    "y_bin = lb.fit(Yenc)\n",
    "ClassMap_AXIS = {i:c for i,c in enumerate(lbe.classes_)}"
   ],
   "id": "8e9179e2af7f0304",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ClassMap_AXIS",
   "id": "6bfc27e965a32c03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RES_LIST_AXIS, RES_AXIS_DF = tree_utils.training_loop(X, Yenc, splitter, \n",
    "                              PipeDict, \n",
    "                              use_class_weights=USE_CLASS_WEIGHT, ClassMap=ClassMap_AXIS,\n",
    "                              num_splits=num_splits, num_repeats=num_repeats, make_df=True)"
   ],
   "id": "69d92546487d7101",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "RES_AXIS_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS.parquet\"))",
   "id": "cbac039b03dfa334",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### make roc and precision recall curves",
   "id": "b83ba3a4c13171e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Y.value_counts()",
   "id": "6bedd5c9af9153e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_classes = len(lb.classes_)\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']"
   ],
   "id": "5faf16ee09a870e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ClassMap_AXIS, lbe.classes_",
   "id": "9d5dbe13ce610c8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "PLOTS_AXIS = tree_utils.make_plots(RES_LIST_AXIS, lb,  n_classes, \n",
    "                                   colors, ClassMap_AXIS,\n",
    "                                   output_map=os.path.join(data_path, fstring),\n",
    "                                   show_plot=False, \n",
    "                                   plot_title=\"Heart Axis\")\n",
    "perf_list = tree_utils.get_performance(RES_LIST_AXIS, threshold=1/n_classes,\n",
    "                                       ClassMap=ClassMap_AXIS, binarizer=lb)\n",
    "PERF_AXIS = pd.DataFrame(perf_list)"
   ],
   "id": "2b6620bf0e4e8e07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "PERF_AXIS[['f1', 'precision', 'recall', 'specificity', 'model', 'Class']].groupby(['model', 'Class']).mean()",
   "id": "276127563cf1a9a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tree_utils.net_benefit_curve_plot(RES_AXIS_DF, true_col_prefix='Y_test',\n",
    "                                     pred_col_prefix='Y_pred',\n",
    "                                     output_path=os.path.join(data_path, fstring),\n",
    "                                     threshold_steps=20, \n",
    "                                     xlim=[0,0.5],\n",
    "                                     ylim=[-1,1],\n",
    "                                     plot_title=\"Heart Axis\")\n",
    "\n",
    "tree_utils.calibration_curve_plot(RES_AXIS_DF,\n",
    "                                   true_col_prefix='Y_test',\n",
    "                                   pred_col_prefix='Y_pred',\n",
    "                                   output_path=os.path.join(data_path, fstring),\n",
    "                                   n_bins=10,\n",
    "                                   plot_title=\"Heart Axis\",\n",
    "                                   show_plot=True)"
   ],
   "id": "fb9016e8da8d17b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Muscle model",
   "id": "a040b2c8e742961e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target_col = \"Diagnosis\"\n",
    "target_inclusion = ['SR','LVH','Microvoltages']\n",
    "Reduction_map = {'Microvoltages': 'Disease', \n",
    "                 'LVH': 'Disease',\n",
    "                 'SR': 'Normal'}\n",
    "if ALL_FEATURES:\n",
    "    features_to_use = []\n",
    "else:\n",
    "    features_to_use = ['qrs_vector mean lead_0',\n",
    "                     'qrs_ampl mean lead_0',\n",
    "                     'qrs_vector mean lead_1',\n",
    "                     'qrs_ampl mean lead_1',\n",
    "                     'qrs_vector mean lead_2',\n",
    "                     'qrs_ampl mean lead_2',\n",
    "                     'qrs_vector mean lead_3',\n",
    "                     'qrs_ampl mean lead_3',\n",
    "                     'qrs_vector mean lead_4',\n",
    "                     'qrs_ampl mean lead_4',\n",
    "                     'qrs_vector mean lead_5',\n",
    "                     'qrs_ampl mean lead_5',\n",
    "                     'qrs_vector mean lead_6',\n",
    "                     'qrs_ampl mean lead_6',\n",
    "                     'qrs_vector mean lead_7',\n",
    "                     'qrs_ampl mean lead_7',\n",
    "                     'morphology lead_0',\n",
    "                     'morphology lead_1',\n",
    "                     'morphology lead_2',\n",
    "                     'morphology lead_3',\n",
    "                     'morphology lead_4',\n",
    "                     'morphology lead_5',\n",
    "                     'morphology lead_6',\n",
    "                     'morphology lead_7']"
   ],
   "id": "9d1fd628d813459a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if len(features_to_use)==0:\n",
    "    meas_cols = [c for c in DATA.columns if ('Dataset' not in c) \n",
    "                 & (target_col not in c)\n",
    "                 & (\"Heart Axis Diagnosis\" not in c)]\n",
    "else:\n",
    "    meas_cols = features_to_use\n",
    "    \n",
    "fstring = f\"MUSCLE_{CLASS_WEIGHT_STRING}{ALL_FEATURES_STRING}{REDUCED_LABEL_STRING}\"\n",
    "os.makedirs(os.path.join(data_path, fstring), exist_ok=True)\n",
    "\n",
    "MUSCLE_DATA = DATA.loc[DATA[target_col].apply(lambda x: any([c in x for c in target_inclusion])), \n",
    "                       meas_cols+[target_col]+['Dataset']]\n",
    "\n",
    "MUSCLE_DATA = MUSCLE_DATA.assign(Diagnosis=MUSCLE_DATA.Diagnosis.map({\n",
    "                                                            'SR': 'SR',\n",
    "                                                            'Microvoltages': 'Microvoltages',\n",
    "                                                            'LVH': 'LVH',\n",
    "                                                            'LAFB , LVH': 'LVH',\n",
    "                                                            'Microvoltages , BF': 'Microvoltages',\n",
    "                                                            'Microvoltages , RBBB': 'Microvoltages',\n",
    "                                                            'Microvoltages , LAFB': 'Microvoltages',\n",
    "                                                            'LVH , BF': 'LVH',\n",
    "                                                            'LVH , RBBB': 'LVH',\n",
    "                                                            'LVH , LBBB': 'LVH'\n",
    "                                                        }))\n",
    "\n",
    "if USE_REDUCED_LABELS:\n",
    "    MUSCLE_DATA.loc[:, target_col] = MUSCLE_DATA[target_col].map(Reduction_map)\n",
    "    \n",
    "MUSCLE_DATA.to_parquet(os.path.join(data_path, fstring, f'DATA.parquet'))\n",
    "MUSCLE_DATA = MUSCLE_DATA.drop('Dataset', axis=1)"
   ],
   "id": "26f49ef36ab8692",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training loop",
   "id": "a9cc5bc4b0e4bb08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "OrdEncoder = OrdinalEncoder(\n",
    "    categories='auto',\n",
    "    dtype=int,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-2,\n",
    "    encoded_missing_value=-1,\n",
    ")\n",
    "PipeOrdEncoder = ColumnTransformer([(\"cat_encoder\", OrdEncoder, morphology_columns)], remainder='passthrough')\n",
    "le_pipe_rf = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"RandomForest\", RandomForestClassifier(**randomforest_kwargs))])\n",
    "le_pipe_gbc = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"GradientBoosting\", GradientBoostingClassifier(**gradientboosting_kwargs))])\n",
    "le_pipe_xgb = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"XGBoost\", XGBClassifier(**xgboost_kwargs))])\n",
    "le_pipe_dt = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"DecisionTree\", DecisionTreeClassifier(**decisiontree_kwargs))])\n",
    "\n",
    "PipeDict = {\n",
    "    'rf': le_pipe_rf,\n",
    "    'gbc': le_pipe_gbc,\n",
    "    'xgb': le_pipe_xgb,\n",
    "    'dt': le_pipe_dt    \n",
    "}"
   ],
   "id": "cf26a5da6518a0fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits=num_splits, n_repeats=num_repeats, random_state=7)\n",
    "X = MUSCLE_DATA.iloc[:, :-1]\n",
    "Y = MUSCLE_DATA.iloc[:,-1]\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lbe = LabelEncoder()\n",
    " #(RES_LIST_AXIS[0]['Y_test'])\n",
    "Yenc = lbe.fit_transform(Y.values) #(RES_LIST_AXIS[0]['Y_test'])\n",
    "lb.fit(Yenc)\n",
    "ClassMap_MUSCLE = {i:c for i,c in enumerate(lbe.classes_)}"
   ],
   "id": "65feafe3a20f9a45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ClassMap_MUSCLE",
   "id": "5f0121096cf31e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RES_LIST_MUSCLE, RES_MUSCLE_DF = tree_utils.training_loop(X, Yenc, splitter, PipeDict, \n",
    "                                    use_class_weights=USE_CLASS_WEIGHT, ClassMap=ClassMap_MUSCLE,\n",
    "                                    num_splits=num_splits, num_repeats=num_repeats, make_df=True)"
   ],
   "id": "3cf0fe7e343dfeab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "RES_MUSCLE_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS.parquet\"))",
   "id": "73a6cbf256be55f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### make roc and precision recall curves",
   "id": "2ce70375c9da0869"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Y.value_counts()",
   "id": "a24aa3b0b5e40444",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_classes = len(lb.classes_)\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']"
   ],
   "id": "a22535ee56ddb698",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "PLOTS_MUSCLE = tree_utils.make_plots(RES_LIST_MUSCLE, lb,  n_classes, colors,\n",
    "                                     ClassMap_MUSCLE,\n",
    "                                     output_map=os.path.join(data_path, fstring),\n",
    "                                     show_plot=False,\n",
    "                                     plot_title=\"Heart Muscle\")\n",
    "\n",
    "perf_list = tree_utils.get_performance(RES_LIST_MUSCLE, threshold=1/n_classes, \n",
    "                                       ClassMap=ClassMap_MUSCLE, binarizer=lb)\n",
    "PERF_MUSCLE = pd.DataFrame(perf_list)"
   ],
   "id": "b1e8cc3894802668",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "PERF_MUSCLE[['f1', 'precision', 'recall', 'specificity', 'model', 'Class']].groupby(['model', 'Class']).mean()",
   "id": "3d3b70009b26d9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tree_utils.net_benefit_curve_plot(RES_MUSCLE_DF, true_col_prefix='Y_test',\n",
    "                                     pred_col_prefix='Y_pred',\n",
    "                                     output_path=os.path.join(data_path, fstring),\n",
    "                                     threshold_steps=20, \n",
    "                                     xlim=[0,0.5],\n",
    "                                     ylim=[-1,1],\n",
    "                                     plot_title=\"Heart Muscle\")\n",
    "\n",
    "tree_utils.calibration_curve_plot(RES_MUSCLE_DF,\n",
    "                                   true_col_prefix='Y_test',\n",
    "                                   pred_col_prefix='Y_pred',\n",
    "                                   output_path=os.path.join(data_path, fstring),\n",
    "                                   n_bins=10,\n",
    "                                   plot_title=\"Heart Muscle\",\n",
    "                                   show_plot=True)"
   ],
   "id": "dbdc874b90d7ca84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conduction model",
   "id": "f288241a0f7e1e34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:00:54.733827Z",
     "start_time": "2024-07-26T15:00:54.612329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_col = \"Diagnosis\"\n",
    "target_inclusion = ['BF', 'LBBB','RBBB','LAFB', 'SR']\n",
    "Reduction_map = {'BF': 'Disease', \n",
    "                 'LBBB': 'Disease', \n",
    "                 'RBBB': 'Disease',\n",
    "                 'LAFB': 'Disease',\n",
    "                 'SR': 'Normal'}\n",
    "features_to_use = []"
   ],
   "id": "8208fa606e99709c",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:00:55.970840Z",
     "start_time": "2024-07-26T15:00:55.218743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(features_to_use)==0:\n",
    "    meas_cols = [c for c in DATA.columns if ('Dataset' not in c) \n",
    "                 & (target_col not in c)\n",
    "                 & (\"Heart Axis Diagnosis\" not in c)]\n",
    "else:\n",
    "    meas_cols = features_to_use\n",
    "    \n",
    "fstring = f\"CONDUCTION{CLASS_WEIGHT_STRING}{ALL_FEATURES_STRING}{REDUCED_LABEL_STRING}\"\n",
    "os.makedirs(os.path.join(data_path, fstring), exist_ok=True)\n",
    "\n",
    "CONDUCTION_DATA = DATA.loc[DATA[target_col].apply(lambda x: any([c in x for c in target_inclusion])),  meas_cols+[target_col]+['Dataset']]\n",
    "\n",
    "CONDUCTION_DATA = CONDUCTION_DATA.assign(Diagnosis=CONDUCTION_DATA.Diagnosis.map({\n",
    "                                                                'SR': 'SR',\n",
    "                                                                'BF': 'BF',\n",
    "                                                                'RBBB': 'RBBB',\n",
    "                                                                'LBBB': 'LBBB',\n",
    "                                                                'LAFB': 'LAFB',\n",
    "                                                                'LAFB , LVH': 'LAFB',\n",
    "                                                                'Microvoltages , BF': 'BF',\n",
    "                                                                'Microvoltages , RBBB': 'RBBB',\n",
    "                                                                'Microvoltages , LAFB': 'LAFB', \n",
    "                                                                'LVH , BF': 'BF',\n",
    "                                                                'LVH , RBBB': 'RBBB',\n",
    "                                                                'LVH , LBBB': 'LBBB'\n",
    "                                                            }))\n",
    "if USE_REDUCED_LABELS:\n",
    "    CONDUCTION_DATA.loc[:, target_col] = CONDUCTION_DATA[target_col].map(Reduction_map)\n",
    "    \n",
    "CONDUCTION_DATA.to_parquet(os.path.join(data_path, fstring, 'CONDUCTION.parquet'))\n",
    "CONDUCTION_DATA = CONDUCTION_DATA.drop('Dataset', axis=1)"
   ],
   "id": "13961e3c61f51dcf",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:00:56.233646Z",
     "start_time": "2024-07-26T15:00:56.096179Z"
    }
   },
   "cell_type": "code",
   "source": "# ['BF', 'LBBB','RBBB','LAFB', 'SR']\n",
   "id": "aad18959f52ed7e8",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training loop",
   "id": "cc77f778e5ba6dc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:00:57.439873Z",
     "start_time": "2024-07-26T15:00:57.304899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "OrdEncoder = OrdinalEncoder(\n",
    "    categories='auto',\n",
    "    dtype=int,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-2,\n",
    "    encoded_missing_value=-1,\n",
    ")\n",
    "PipeOrdEncoder = ColumnTransformer([(\"cat_encoder\", OrdEncoder, morphology_columns)], remainder='passthrough')\n",
    "le_pipe_rf = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"RandomForest\", RandomForestClassifier(**randomforest_kwargs))])\n",
    "le_pipe_gbc = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"GradientBoosting\", GradientBoostingClassifier(**gradientboosting_kwargs))])\n",
    "le_pipe_xgb = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"XGBoost\", XGBClassifier(**xgboost_kwargs))])\n",
    "le_pipe_dt = Pipeline([\n",
    "    (\"CatEncoder\", PipeOrdEncoder), \n",
    "    (\"Impute\", IterativeImputer(**impute_kwargs)),\n",
    "    (\"DecisionTree\", DecisionTreeClassifier(**decisiontree_kwargs))])\n",
    "\n",
    "PipeDict = {\n",
    "    'rf': le_pipe_rf,\n",
    "    'gbc': le_pipe_gbc,\n",
    "    'xgb': le_pipe_xgb,\n",
    "    'dt': le_pipe_dt    \n",
    "}"
   ],
   "id": "8787db8d9325d2fd",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:00:58.292368Z",
     "start_time": "2024-07-26T15:00:58.134368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits=num_splits, n_repeats=num_repeats, random_state=7)\n",
    "X = CONDUCTION_DATA.iloc[:, :-1]\n",
    "Y = CONDUCTION_DATA.iloc[:,-1]\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lbe = LabelEncoder()\n",
    "Yenc = lbe.fit_transform(Y)\n",
    "lb.fit(Yenc)    \n",
    "ClassMap_CONDUCTION = {i:c for i,c in enumerate(lbe.classes_)}"
   ],
   "id": "6c063168d558da7a",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:00:59.036374Z",
     "start_time": "2024-07-26T15:00:58.885873Z"
    }
   },
   "cell_type": "code",
   "source": "ClassMap_CONDUCTION",
   "id": "7d2e799addecd3dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Disease', 1: 'Normal'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:03:12.120224Z",
     "start_time": "2024-07-26T15:01:02.672403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RES_LIST_CONDUCTION, RES_CONDUCTION_DF = tree_utils.training_loop(X, Yenc, splitter, PipeDict,\n",
    "                                    use_class_weights=USE_CLASS_WEIGHT, \n",
    "                                    ClassMap=ClassMap_CONDUCTION,\n",
    "                                    num_splits=num_splits,num_repeats=num_repeats,\n",
    "                                    make_df=True)"
   ],
   "id": "4392a30a2cbe5aea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:09<00:00, 64.65s/it]\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:03:12.398104Z",
     "start_time": "2024-07-26T15:03:12.122725Z"
    }
   },
   "cell_type": "code",
   "source": "RES_CONDUCTION_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS.parquet\"))",
   "id": "85e6da4aa953ca6b",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### make roc and precision recall curves",
   "id": "fb9808561967a6d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:03:12.552623Z",
     "start_time": "2024-07-26T15:03:12.401134Z"
    }
   },
   "cell_type": "code",
   "source": "Y.value_counts()",
   "id": "4ae73bcfe00c24c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "Disease    702\n",
       "Normal     649\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:03:12.692116Z",
     "start_time": "2024-07-26T15:03:12.555612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_classes = len(lb.classes_)\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']"
   ],
   "id": "9ec0e390ff9b9722",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "11cf6bcf2eb9d9de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:03:13.141360Z",
     "start_time": "2024-07-26T15:03:12.694613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PLOTS_CONDUCTION = tree_utils.make_plots(RES_LIST_CONDUCTION, lb,  n_classes, colors,\n",
    "                                         ClassMap_CONDUCTION,\n",
    "                                         output_map=os.path.join(data_path, fstring),\n",
    "                                         show_plot=False,\n",
    "                                         plot_title=\"Heart Conduction\")\n",
    "\n",
    "perf_list = tree_utils.get_performance(RES_LIST_CONDUCTION, threshold=1/n_classes, \n",
    "                                       ClassMap=ClassMap_CONDUCTION, binarizer=lb)\n",
    "\n",
    "PERF_CONDUCTION = pd.DataFrame(perf_list)"
   ],
   "id": "59c90bef553b4566",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:03:13.280659Z",
     "start_time": "2024-07-26T15:03:13.143656Z"
    }
   },
   "cell_type": "code",
   "source": "PERF_CONDUCTION[['f1', 'precision', 'recall', 'specificity', 'model', 'Class']].groupby(['model', 'Class']).mean()",
   "id": "8c727dfb89c2dfb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            f1  precision    recall  specificity\n",
       "model Class                                                     \n",
       "DT    Disease         0.864529   0.849783  0.879820     0.467099\n",
       "GBT   Disease/Normal  0.857952   0.837178  0.879791     0.411267\n",
       "RF    Disease/Normal  0.898318   0.892232  0.904497     0.467099\n",
       "XGB   Disease/Normal  0.900777   0.879647  0.922963     0.379263"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>Disease</th>\n",
       "      <td>0.864529</td>\n",
       "      <td>0.849783</td>\n",
       "      <td>0.879820</td>\n",
       "      <td>0.467099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT</th>\n",
       "      <th>Disease/Normal</th>\n",
       "      <td>0.857952</td>\n",
       "      <td>0.837178</td>\n",
       "      <td>0.879791</td>\n",
       "      <td>0.411267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>Disease/Normal</th>\n",
       "      <td>0.898318</td>\n",
       "      <td>0.892232</td>\n",
       "      <td>0.904497</td>\n",
       "      <td>0.467099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <th>Disease/Normal</th>\n",
       "      <td>0.900777</td>\n",
       "      <td>0.879647</td>\n",
       "      <td>0.922963</td>\n",
       "      <td>0.379263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T15:03:16.301918Z",
     "start_time": "2024-07-26T15:03:13.283156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tree_utils.net_benefit_curve_plot(RES_CONDUCTION_DF, true_col_prefix='Y_test',\n",
    "                                     pred_col_prefix='Y_pred',\n",
    "                                     output_path=os.path.join(data_path, fstring),\n",
    "                                     threshold_steps=20, \n",
    "                                     xlim=[0,0.5],\n",
    "                                     ylim=[-1,1],\n",
    "                                     plot_title=\"Heart Conduction\")\n",
    "\n",
    "tree_utils.calibration_curve_plot(RES_CONDUCTION_DF,\n",
    "                                   true_col_prefix='Y_test',\n",
    "                                   pred_col_prefix='Y_pred',\n",
    "                                   output_path=os.path.join(data_path, fstring),\n",
    "                                   n_bins=10,\n",
    "                                   plot_title=\"Heart Conduction\",\n",
    "                                   show_plot=True)"
   ],
   "id": "54d2906bf2a27141",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:163: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all positive' strategy\n",
      "T:\\laupodteam\\AIOS\\Bram\\notebooks\\code_dev\\miniECG_interpretation\\TreeBuilder\\sandbox\\..\\src\\tree_utils.py:167: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  # Calculate net benefit for 'all negative' strategy\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2ad6a50ea3cb0be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base_310)",
   "language": "python",
   "name": "python3_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
