{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#from rulefit import RuleFit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, LogisticRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, TunedThresholdClassifierCV\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "#from category_encoders import JamesSteinEncoder, CatBoostEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "# add ../src to python path\n",
    "sys.path.insert(0, os.path.join(os.path.abspath('.'),'..', 'src'))\n",
    "\n",
    "import tree_utils"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2da11eab31e03653",
   "metadata": {},
   "source": [
    "# Try from sklego.meta import HierarchicalClassifier\n",
    "# hc = HierarchicalClassifier(\n",
    "#    estimator=LogisticRegression(),\n",
    "#    groups=groups\n",
    "#).fit(X, y)\n",
    "#hc.estimators_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b287448247b39c96",
   "metadata": {},
   "source": [
    "data_path =  r\"J:\\Onderzoek\\21-763_rvanes_MiniECG-2-Data\\E_ResearchData\\2_ResearchData\\Analysis\"\n",
    "file_name =  r\"input_decision_tree_complete.pkl\"\n",
    "\n",
    "num_splits = 10\n",
    "num_repeats = 10\n",
    "MAX_FEATURES = 100 # only relevant if USE_LEAD_COMBOS is True\n",
    "USE_CLASS_WEIGHT = False\n",
    "ALL_FEATURES = True\n",
    "USE_REDUCED_LABELS = False\n",
    "USE_CALIBRATED_CLASSIFIER = True\n",
    "USE_LEAD_COMBOS = False\n",
    "COMBO_WITH_FEATURE_FILTER = False\n",
    "\n",
    "CatEncoderType = 'onehot' # 'onehot' or 'ordinal'\n",
    "\n",
    "ALL_FEATURES_STRING = \"_useAllvars\" if ALL_FEATURES else \"\"\n",
    "CLASS_WEIGHT_STRING = \"_withClassWeights\" if USE_CLASS_WEIGHT else \"\"\n",
    "REDUCED_LABEL_STRING = \"_withReducedLabels\" if USE_REDUCED_LABELS else \"\"\n",
    "CALIBRATED_CLASSIFIER_STRING = \"_withCalibratedClassifier\" if USE_CALIBRATED_CLASSIFIER else \"\"\n",
    "FEATURE_COMBO_STRING = \"_withLeadCombos\" if USE_LEAD_COMBOS else \"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c8568e7c45a3b69",
   "metadata": {},
   "source": [
    "with open(os.path.join(data_path, file_name), 'rb') as f:\n",
    "    input_decision_tree_complete = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d358b6d09bb7abf",
   "metadata": {},
   "source": [
    "DATA = pd.DataFrame(input_decision_tree_complete).T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f5ce94c57a4b896e",
   "metadata": {},
   "source": [
    "out_folder =r\"J:\\Onderzoek\\21-763_rvanes_MiniECG-2-Data\\E_ResearchData\\2_ResearchData\\Parquet\"\n",
    "DATA.to_parquet(os.path.join(out_folder,'DATA.parquet'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "140fe6b8f4ccc11c",
   "metadata": {},
   "source": [
    "morphology_columns = [c for c in DATA.columns if 'morphology' in c]\n",
    "lead_columns = [c for c in DATA.columns if ('lead' in c) & ('morphology' not in c)]\n",
    "\n",
    "for c in morphology_columns:\n",
    "    DATA.loc[:, c] = DATA[c].apply(lambda x: x[0].strip(\",\").strip(\" \"))\n",
    "    DATA.loc[:, c] = DATA[c].apply(lambda x: x if x.strip()!=\"\" else \"none\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eda403d789cb7adb",
   "metadata": {},
   "source": [
    "morphology_values = []\n",
    "for c in morphology_columns:\n",
    "    morphology_values.extend(DATA[c].unique().tolist())\n",
    "morphology_values = list(set(morphology_values))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9272e8b914105713",
   "metadata": {},
   "source": [
    "ComboFunctions = {\n",
    "    'AbsFactor' : lambda x,y: abs(x-y) # np.sign(x*y)*np.sqrt(np.abs(x*y))\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40f50f4d6b9d1d77",
   "metadata": {},
   "source": [
    "if USE_LEAD_COMBOS:\n",
    "    Enriched_DF, new_columns = tree_utils.create_feature_combinations(df=DATA[lead_columns], \n",
    "                                           lambda_functions=ComboFunctions)\n",
    "    DATA = DATA.drop(lead_columns, axis=1)\n",
    "    DATA = pd.concat([DATA, Enriched_DF], axis=1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b22bea538597a99",
   "metadata": {},
   "source": [
    "# Model prepping"
   ]
  },
  {
   "cell_type": "code",
   "id": "6004219c54779520",
   "metadata": {},
   "source": [
    "# TODO: need to add a feature combiner, perhaps use PySR or GpLearn, focus on vectors\n",
    "\n",
    "impute_kwargs = {\n",
    "    'estimator': LinearRegression(), \n",
    "    'random_state':7,\n",
    "    'imputation_order': 'ascending', \n",
    "    'skip_complete': True,\n",
    "    'max_iter': 2000,\n",
    "    'initial_strategy': 'median',\n",
    "    'add_indicator': True\n",
    "}\n",
    "gradientboosting_kwargs = {\n",
    "    'n_estimators': 500, \n",
    "    'max_depth': 10, \n",
    "    'learning_rate':0.01,\n",
    "    'max_leaf_nodes':40,\n",
    "    'random_state': 7\n",
    "}\n",
    "randomforest_kwargs = {\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 10, \n",
    "    'min_samples_leaf': 10,\n",
    "    'random_state': 7\n",
    "}\n",
    "rulefit_kwargs={\n",
    "    'tree_size': 10,\n",
    "    'max_rules': 100,\n",
    "    'tree_generator': GradientBoostingClassifier(**gradientboosting_kwargs)\n",
    "}\n",
    "decisiontree_kwargs = {\n",
    "    'criterion':'gini', \n",
    "    'splitter':'best', \n",
    "    'max_depth':5, \n",
    "    'min_samples_split':10, \n",
    "    'min_samples_leaf': 5, \n",
    "    'min_weight_fraction_leaf':0.05, \n",
    "    'max_features':None, \n",
    "    'random_state':7, \n",
    "    'max_leaf_nodes':50,\n",
    "    'class_weight': 'balanced'\n",
    "}\n",
    "xgboost_kwargs = {\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 6,\n",
    "    'max_leaves': 50,\n",
    "    'learning_rate': 2e-3,\n",
    "    'gamma': 0.4,\n",
    "    'subsample': 0.55,\n",
    "    'colsample_bytree':0.85,\n",
    "    'reg_alpha': 0.005\n",
    "}\n",
    "logistic_kwargs = {\n",
    "    'penalty': 'elasticnet', \n",
    "    'dual': False, \n",
    "    'tol': 0.0001, \n",
    "    'C':1.0, \n",
    "    'fit_intercept': True, \n",
    "    'intercept_scaling':1, \n",
    "    'class_weight':None, \n",
    "    'random_state':7, \n",
    "    'solver': 'saga', \n",
    "    'max_iter':2000, \n",
    "    'verbose': 0, \n",
    "    'warm_start': False, \n",
    "    'n_jobs':-1, \n",
    "    'l1_ratio':0.5\n",
    "}\n",
    "calibration_kwargs ={\n",
    "    'method': 'sigmoid',\n",
    "    'n_jobs': -1, \n",
    "    'ensemble': True,\n",
    "    'cv': 5\n",
    "}\n",
    "ordinal_encoder_kwargs = {\n",
    "    'categories': 'auto',\n",
    "    'dtype': int,\n",
    "    'handle_unknown':'use_encoded_value',\n",
    "    'unknown_value': -2,\n",
    "    'encoded_missing_value': -1\n",
    "}\n",
    "onehot_kwargs = {\n",
    "    'drop': 'first', \n",
    "    'sparse_output': False,\n",
    "    'min_frequency': 0.15,\n",
    "    'handle_unknown': 'ignore'\n",
    "}\n",
    "\n",
    "combine_kwargs = {}\n",
    "combine_kwargs['impute'] = impute_kwargs.copy()\n",
    "combine_kwargs['impute']['estimator'] = str(type(combine_kwargs['impute']['estimator']))\n",
    "combine_kwargs['decisiontree'] = decisiontree_kwargs\n",
    "combine_kwargs['xgboost'] = xgboost_kwargs\n",
    "combine_kwargs['logistic'] = logistic_kwargs\n",
    "combine_kwargs['calibration'] = calibration_kwargs\n",
    "\n",
    "if CatEncoderType == 'onehot':\n",
    "    combine_kwargs['catencoder'] = onehot_kwargs.copy()\n",
    "    combine_kwargs['catencoder']['type'] = 'onehot'\n",
    "elif CatEncoderType == 'ordinal':\n",
    "    combine_kwargs['catencoder'] = ordinal_encoder_kwargs.copy()\n",
    "    combine_kwargs['catencoder']['type'] = 'ordinal'\n",
    "else:\n",
    "    raise ValueError(\"Invalid CatEncoderType\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b17720ea4e5a9c0f",
   "metadata": {},
   "source": [
    "OrdEncoder = OrdinalEncoder(**ordinal_encoder_kwargs)\n",
    "OneHot = OneHotEncoder(**onehot_kwargs)\n",
    "\n",
    "if CatEncoderType == 'onehot':\n",
    "    _catencoder = OneHot\n",
    "else:\n",
    "    _catencoder = OrdEncoder\n",
    "\n",
    "\n",
    "PipeOrdEncoder = ColumnTransformer([(\"cat_encoder\", _catencoder, morphology_columns)],\n",
    "                                       remainder='passthrough')\n",
    "\n",
    "FFilter = SelectFromModel(estimator=LogisticRegression(**logistic_kwargs),\n",
    "                            max_features=MAX_FEATURES)\n",
    "\n",
    "_imputer = IterativeImputer(**impute_kwargs)\n",
    "\n",
    "if ALL_FEATURES:\n",
    "    _cat_enc = PipeOrdEncoder\n",
    "else:\n",
    "    _cat_enc = None\n",
    "\n",
    "if (USE_LEAD_COMBOS) & (COMBO_WITH_FEATURE_FILTER):\n",
    "    _feature_filter = FFilter\n",
    "    _imputer = SimpleImputer(strategy='median', add_indicator=True)\n",
    "else:\n",
    "    _feature_filter = VarianceThreshold()\n",
    "\n",
    "if USE_CALIBRATED_CLASSIFIER:\n",
    "    RF_clf = CalibratedClassifierCV(RandomForestClassifier(**randomforest_kwargs), \n",
    "                                    **calibration_kwargs)\n",
    "    GBC_clf = CalibratedClassifierCV(GradientBoostingClassifier(**gradientboosting_kwargs),\n",
    "                                     **calibration_kwargs)\n",
    "    XGB_clf = CalibratedClassifierCV(XGBClassifier(**xgboost_kwargs),\n",
    "                                     **calibration_kwargs)\n",
    "    DT_clf = CalibratedClassifierCV(DecisionTreeClassifier(**decisiontree_kwargs),\n",
    "                                     **calibration_kwargs)\n",
    "    LR_clf = CalibratedClassifierCV(LogisticRegression(**logistic_kwargs),\n",
    "                                     **calibration_kwargs)\n",
    "else:\n",
    "    RF_clf = RandomForestClassifier(**randomforest_kwargs)\n",
    "    GBC_clf = GradientBoostingClassifier(**gradientboosting_kwargs)\n",
    "    XGB_clf = tree_utils.GenericCalibratedClassifier(XGBClassifier(**xgboost_kwargs))\n",
    "    DT_clf = DecisionTreeClassifier(**decisiontree_kwargs)\n",
    "    LR_clf = LogisticRegression(**logistic_kwargs)\n",
    "\n",
    "le_pipe_rf = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", _imputer),\n",
    "    (\"FeatureFilter\", _feature_filter),\n",
    "    (\"RandomForest\", RF_clf)])\n",
    "\n",
    "le_pipe_gbc = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", _imputer),\n",
    "    (\"FeatureFilter\", _feature_filter),\n",
    "    (\"GradientBoosting\", GBC_clf)])\n",
    "\n",
    "le_pipe_xgb = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", _imputer),\n",
    "    (\"FeatureFilter\", _feature_filter),\n",
    "    (\"XGBoost\", XGB_clf)])\n",
    "\n",
    "le_pipe_dt = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", _imputer),\n",
    "    (\"FeatureFilter\", _feature_filter),\n",
    "    (\"DecisionTree\", DT_clf)])\n",
    "\n",
    "le_pipe_lr = Pipeline([\n",
    "    (\"CatEncoder\", _cat_enc),\n",
    "    (\"Impute\", _imputer),\n",
    "    (\"FeatureFilter\", _feature_filter),\n",
    "    (\"LogisticRegression\", LR_clf)])\n",
    "\n",
    "PipeDict = {}\n",
    "#PipeDict['rf'] = le_pipe_rf\n",
    "#PipeDict['gbc'] = le_pipe_gbc\n",
    "PipeDict['xgb'] = le_pipe_xgb\n",
    "PipeDict['dt'] = le_pipe_dt\n",
    "PipeDict['lr'] = le_pipe_lr\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5af910b8b1a3657e",
   "metadata": {},
   "source": [
    "# Axis model"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b0a8c5759074ef9",
   "metadata": {},
   "source": [
    "target_col = \"Heart Axis Diagnosis\"\n",
    "if not USE_REDUCED_LABELS:\n",
    "    target_inclusion = ['Left', 'Normal', 'Right']\n",
    "else:\n",
    "    target_inclusion = ['Left', 'Normal', 'Right', 'Extreme']\n",
    "    \n",
    "Reduction_map = {'Left': 'Disease', \n",
    "                 'Right': 'Disease',\n",
    "                 'Extreme': 'Disease',\n",
    "                 'Normal': 'Normal'}\n",
    "if ALL_FEATURES:\n",
    "    features_to_use = []\n",
    "else:\n",
    "    features_to_use = ['qrs_vector mean lead_0',\n",
    "                     'p_vector mean lead_0',\n",
    "                     't_vector mean lead_0',\n",
    "                     'qrs_vector mean lead_1',\n",
    "                     'p_vector mean lead_1',\n",
    "                     't_vector mean lead_1',\n",
    "                     'qrs_vector mean lead_2',\n",
    "                     'p_vector mean lead_2',\n",
    "                     't_vector mean lead_2',\n",
    "                     'qrs_vector mean lead_3',\n",
    "                     'p_vector mean lead_3',\n",
    "                     't_vector mean lead_3',\n",
    "                     'qrs_vector mean lead_4',\n",
    "                     'p_vector mean lead_4',\n",
    "                     't_vector mean lead_4',\n",
    "                     'qrs_vector mean lead_5',\n",
    "                     'p_vector mean lead_5',\n",
    "                     't_vector mean lead_5',\n",
    "                     'qrs_vector mean lead_6',\n",
    "                     'p_vector mean lead_6',\n",
    "                     't_vector mean lead_6',\n",
    "                     'qrs_vector mean lead_7',\n",
    "                     'p_vector mean lead_7',\n",
    "                     't_vector mean lead_7'\n",
    "                       ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aea10a2f941fc161",
   "metadata": {},
   "source": [
    "if len(features_to_use)==0:\n",
    "    meas_cols = [c for c in DATA.columns if ('Dataset' not in c) \n",
    "                 & (target_col not in c)\n",
    "                 & ('Diagnosis' not in c)]\n",
    "else:\n",
    "    meas_cols = features_to_use\n",
    "    \n",
    "fstring = f\"AXIS_{CLASS_WEIGHT_STRING}{ALL_FEATURES_STRING}{REDUCED_LABEL_STRING}{CALIBRATED_CLASSIFIER_STRING}{FEATURE_COMBO_STRING}_CatEnc{CatEncoderType}\"\n",
    "os.makedirs(os.path.join(data_path, fstring), exist_ok=True)\n",
    "\n",
    "AXIS_DATA = DATA.loc[DATA[target_col].isin(target_inclusion), meas_cols+[target_col]+['Dataset']]\n",
    "if USE_REDUCED_LABELS:\n",
    "    AXIS_DATA.loc[:, target_col] = AXIS_DATA[target_col].map(Reduction_map)\n",
    "    \n",
    "AXIS_DATA.to_parquet(os.path.join(data_path, fstring, 'DATA.parquet'))\n",
    "AXIS_DATA = AXIS_DATA.drop('Dataset', axis=1)\n",
    "\n",
    "json.dump(combine_kwargs, open(os.path.join(data_path, fstring, 'settings.json'), 'w'))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8b76eb1c95fd94d",
   "metadata": {},
   "source": [
    "### TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "id": "8e9179e2af7f0304",
   "metadata": {},
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits=num_splits, n_repeats=num_repeats, random_state=7)\n",
    "\n",
    "X = AXIS_DATA.iloc[:, :-1]\n",
    "Y = AXIS_DATA.iloc[:,-1]\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lbe = LabelEncoder()\n",
    "\n",
    " #(RES_LIST_AXIS[0]['Y_test'])\n",
    "Yenc = lbe.fit_transform(Y.values) #(RES_LIST_AXIS[0]['Y_test'])\n",
    "y_bin = lb.fit(Yenc)\n",
    "ClassMap_AXIS = {i:c for i,c in enumerate(lbe.classes_)}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6bfc27e965a32c03",
   "metadata": {},
   "source": [
    "ClassMap_AXIS"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69d92546487d7101",
   "metadata": {},
   "source": [
    "RES_LIST_AXIS, RES_AXIS_DF, RES_AXIS_INDCS_DF = tree_utils.training_loop(X, Yenc, splitter, \n",
    "                              PipeDict, \n",
    "                              use_class_weights=USE_CLASS_WEIGHT, ClassMap=ClassMap_AXIS,\n",
    "                              num_splits=num_splits, num_repeats=num_repeats, make_df=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b83ba3a4c13171e7",
   "metadata": {},
   "source": [
    "### make roc and precision recall curves"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bedd5c9af9153e5",
   "metadata": {},
   "source": [
    "Y.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5faf16ee09a870e5",
   "metadata": {},
   "source": [
    "n_classes = len(lb.classes_)\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b6620bf0e4e8e07",
   "metadata": {},
   "source": [
    "PLOTS_AXIS = tree_utils.make_plots(RES_LIST_AXIS, lb,  n_classes, \n",
    "                                   colors, ClassMap_AXIS,\n",
    "                                   output_map=os.path.join(data_path, fstring),\n",
    "                                   show_plot=False, \n",
    "                                   models = list(PipeDict.keys()),\n",
    "                                   plot_title=\"Heart Axis\")\n",
    "perf_list = tree_utils.get_performance(RES_LIST_AXIS, \n",
    "                                       threshold=1/n_classes,\n",
    "                                       ClassMap=ClassMap_AXIS, \n",
    "                                       models = list(PipeDict.keys()),\n",
    "                                       binarizer=lb)\n",
    "PERF_AXIS = pd.DataFrame(perf_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "276127563cf1a9a8",
   "metadata": {},
   "source": [
    "PERF_AXIS[['f1', 'precision', 'recall', 'specificity', 'model', 'Class']].groupby(['model', 'Class']).mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb9016e8da8d17b1",
   "metadata": {},
   "source": [
    "tree_utils.net_benefit_curve_plot(RES_AXIS_DF, true_col_prefix='Y_test',\n",
    "                                     pred_col_prefix='Y_pred',\n",
    "                                     output_path=os.path.join(data_path, fstring),\n",
    "                                     threshold_steps=20, \n",
    "                                     xlim=[0,0.5],\n",
    "                                     ylim=[-1,1],\n",
    "                                     plot_title=\"Heart Axis\")\n",
    "\n",
    "tree_utils.calibration_curve_plot(RES_AXIS_DF,\n",
    "                                   true_col_prefix='Y_test',\n",
    "                                   pred_col_prefix='Y_pred',\n",
    "                                   output_path=os.path.join(data_path, fstring),\n",
    "                                   n_bins=10,\n",
    "                                   plot_title=\"Heart Axis\",\n",
    "                                   show_plot=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8603962d21d7db27",
   "metadata": {},
   "source": [
    "RES_AXIS_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS.parquet\"))\n",
    "RES_AXIS_INDCS_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS_w_indices.parquet\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a040b2c8e742961e",
   "metadata": {},
   "source": [
    "# Muscle model"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d1fd628d813459a",
   "metadata": {},
   "source": [
    "target_col = \"Diagnosis\"\n",
    "target_inclusion = ['SR','LVH','Microvoltages']\n",
    "Reduction_map = {'Microvoltages': 'Disease', \n",
    "                 'LVH': 'Disease',\n",
    "                 'SR': 'Normal'}\n",
    "if ALL_FEATURES:\n",
    "    features_to_use = []\n",
    "else:\n",
    "    features_to_use = ['qrs_vector mean lead_0',\n",
    "                     'qrs_ampl mean lead_0',\n",
    "                     'qrs_vector mean lead_1',\n",
    "                     'qrs_ampl mean lead_1',\n",
    "                     'qrs_vector mean lead_2',\n",
    "                     'qrs_ampl mean lead_2',\n",
    "                     'qrs_vector mean lead_3',\n",
    "                     'qrs_ampl mean lead_3',\n",
    "                     'qrs_vector mean lead_4',\n",
    "                     'qrs_ampl mean lead_4',\n",
    "                     'qrs_vector mean lead_5',\n",
    "                     'qrs_ampl mean lead_5',\n",
    "                     'qrs_vector mean lead_6',\n",
    "                     'qrs_ampl mean lead_6',\n",
    "                     'qrs_vector mean lead_7',\n",
    "                     'qrs_ampl mean lead_7',\n",
    "                     'morphology lead_0',\n",
    "                     'morphology lead_1',\n",
    "                     'morphology lead_2',\n",
    "                     'morphology lead_3',\n",
    "                     'morphology lead_4',\n",
    "                     'morphology lead_5',\n",
    "                     'morphology lead_6',\n",
    "                     'morphology lead_7']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9ead5a0bf37213b",
   "metadata": {},
   "source": [
    "_cat_enc = PipeOrdEncoder\n",
    "for k in PipeDict.keys():\n",
    "    PipeDict[k].set_params(CatEncoder= _cat_enc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26f49ef36ab8692",
   "metadata": {},
   "source": [
    "if len(features_to_use)==0:\n",
    "    meas_cols = [c for c in DATA.columns if ('Dataset' not in c) \n",
    "                 & (target_col not in c)\n",
    "                 & (\"Heart Axis Diagnosis\" not in c)]\n",
    "else:\n",
    "    meas_cols = features_to_use\n",
    "    \n",
    "fstring = f\"MUSCLE_{CLASS_WEIGHT_STRING}{ALL_FEATURES_STRING}{REDUCED_LABEL_STRING}{CALIBRATED_CLASSIFIER_STRING}{FEATURE_COMBO_STRING}_CatEnc{CatEncoderType}\"\n",
    "os.makedirs(os.path.join(data_path, fstring), exist_ok=True)\n",
    "\n",
    "MUSCLE_DATA = DATA.loc[DATA[target_col].apply(lambda x: any([c in x for c in target_inclusion])), \n",
    "                       meas_cols+[target_col]+['Dataset']]\n",
    "\n",
    "MUSCLE_DATA = MUSCLE_DATA.assign(Diagnosis=MUSCLE_DATA.Diagnosis.map({\n",
    "                                                            'SR': 'SR',\n",
    "                                                            'Microvoltages': 'Microvoltages',\n",
    "                                                            'LVH': 'LVH',\n",
    "                                                            'LAFB , LVH': 'LVH',\n",
    "                                                            'Microvoltages , BF': 'Microvoltages',\n",
    "                                                            'Microvoltages , RBBB': 'Microvoltages',\n",
    "                                                            'Microvoltages , LAFB': 'Microvoltages',\n",
    "                                                            'LVH , BF': 'LVH',\n",
    "                                                            'LVH , RBBB': 'LVH',\n",
    "                                                            'LVH , LBBB': 'LVH'\n",
    "                                                        }))\n",
    "\n",
    "if USE_REDUCED_LABELS:\n",
    "    MUSCLE_DATA.loc[:, target_col] = MUSCLE_DATA[target_col].map(Reduction_map)\n",
    "    \n",
    "MUSCLE_DATA.to_parquet(os.path.join(data_path, fstring, f'DATA.parquet'))\n",
    "MUSCLE_DATA = MUSCLE_DATA.drop('Dataset', axis=1)\n",
    "\n",
    "json.dump(combine_kwargs, open(os.path.join(data_path, fstring, 'settings.json'), 'w'))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a9cc5bc4b0e4bb08",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "65feafe3a20f9a45",
   "metadata": {},
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits=num_splits, n_repeats=num_repeats, random_state=7)\n",
    "X = MUSCLE_DATA.iloc[:, :-1]\n",
    "Y = MUSCLE_DATA.iloc[:,-1]\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lbe = LabelEncoder()\n",
    " #(RES_LIST_AXIS[0]['Y_test'])\n",
    "Yenc = lbe.fit_transform(Y.values) #(RES_LIST_AXIS[0]['Y_test'])\n",
    "lb.fit(Yenc)\n",
    "ClassMap_MUSCLE = {i:c for i,c in enumerate(lbe.classes_)}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f0121096cf31e5",
   "metadata": {},
   "source": [
    "ClassMap_MUSCLE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3cf0fe7e343dfeab",
   "metadata": {},
   "source": [
    "RES_LIST_MUSCLE, RES_MUSCLE_DF, RES_MUSCLE_INDCS_DF =\\\n",
    "    tree_utils.training_loop(X, Yenc, splitter, PipeDict,  \n",
    "                             use_class_weights=USE_CLASS_WEIGHT, \n",
    "                             ClassMap=ClassMap_MUSCLE, \n",
    "                             num_splits=num_splits, \n",
    "                             num_repeats=num_repeats, \n",
    "                             make_df=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ce70375c9da0869",
   "metadata": {},
   "source": [
    "### make roc and precision recall curves"
   ]
  },
  {
   "cell_type": "code",
   "id": "a24aa3b0b5e40444",
   "metadata": {},
   "source": [
    "Y.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a22535ee56ddb698",
   "metadata": {},
   "source": [
    "n_classes = len(lb.classes_)\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1e8cc3894802668",
   "metadata": {},
   "source": [
    "PLOTS_MUSCLE = tree_utils.make_plots(RES_LIST_MUSCLE, lb,  n_classes, colors,\n",
    "                                     ClassMap_MUSCLE,\n",
    "                                     output_map=os.path.join(data_path, fstring),\n",
    "                                     show_plot=False,\n",
    "                                     models = list(PipeDict.keys()),\n",
    "                                     plot_title=\"Heart Muscle\")\n",
    "\n",
    "perf_list = tree_utils.get_performance(RES_LIST_MUSCLE, \n",
    "                                       threshold=1/n_classes, \n",
    "                                       ClassMap=ClassMap_MUSCLE, \n",
    "                                       models = list(PipeDict.keys()),\n",
    "                                       binarizer=lb)\n",
    "PERF_MUSCLE = pd.DataFrame(perf_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d3b70009b26d9a7",
   "metadata": {},
   "source": [
    "PERF_MUSCLE[['f1', 'precision', 'recall', 'specificity', 'model', 'Class']].groupby(['model', 'Class']).mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbdc874b90d7ca84",
   "metadata": {},
   "source": [
    "tree_utils.net_benefit_curve_plot(RES_MUSCLE_DF, true_col_prefix='Y_test',\n",
    "                                     pred_col_prefix='Y_pred',\n",
    "                                     output_path=os.path.join(data_path, fstring),\n",
    "                                     threshold_steps=20, \n",
    "                                     xlim=[0,0.5],\n",
    "                                     ylim=[-1,1],\n",
    "                                     plot_title=\"Heart Muscle\")\n",
    "\n",
    "tree_utils.calibration_curve_plot(RES_MUSCLE_DF,\n",
    "                                   true_col_prefix='Y_test',\n",
    "                                   pred_col_prefix='Y_pred',\n",
    "                                   output_path=os.path.join(data_path, fstring),\n",
    "                                   n_bins=10,\n",
    "                                   plot_title=\"Heart Muscle\",\n",
    "                                   show_plot=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "649f0b89c46b0941",
   "metadata": {},
   "source": [
    "RES_MUSCLE_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS.parquet\"))\n",
    "RES_MUSCLE_INDCS_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS_w_indices.parquet\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f288241a0f7e1e34",
   "metadata": {},
   "source": [
    "# Conduction model"
   ]
  },
  {
   "cell_type": "code",
   "id": "8208fa606e99709c",
   "metadata": {},
   "source": [
    "target_col = \"Diagnosis\"\n",
    "target_inclusion = ['BF', 'LBBB','RBBB','LAFB', 'SR']\n",
    "Reduction_map = {'BF': 'Disease', \n",
    "                 'LBBB': 'Disease', \n",
    "                 'RBBB': 'Disease',\n",
    "                 'LAFB': 'Disease',\n",
    "                 'SR': 'Normal'}\n",
    "features_to_use = []\n",
    "_cat_enc = PipeOrdEncoder\n",
    "for k in PipeDict.keys():\n",
    "    PipeDict[k].set_params(CatEncoder= _cat_enc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13961e3c61f51dcf",
   "metadata": {},
   "source": [
    "if len(features_to_use)==0:\n",
    "    meas_cols = [c for c in DATA.columns if ('Dataset' not in c) \n",
    "                 & (target_col not in c)\n",
    "                 & (\"Heart Axis Diagnosis\" not in c)]\n",
    "else:\n",
    "    meas_cols = features_to_use\n",
    "    \n",
    "fstring = f\"CONDUCTION{CLASS_WEIGHT_STRING}{ALL_FEATURES_STRING}{REDUCED_LABEL_STRING}{CALIBRATED_CLASSIFIER_STRING}{FEATURE_COMBO_STRING}_CatEnc{CatEncoderType}\"\n",
    "os.makedirs(os.path.join(data_path, fstring), exist_ok=True)\n",
    "\n",
    "CONDUCTION_DATA = DATA.loc[DATA[target_col].apply(lambda x: any([c in x for c in target_inclusion])),  meas_cols+[target_col]+['Dataset']]\n",
    "\n",
    "CONDUCTION_DATA = CONDUCTION_DATA.assign(Diagnosis=CONDUCTION_DATA.Diagnosis.map({\n",
    "                                                                'SR': 'SR',\n",
    "                                                                'BF': 'BF',\n",
    "                                                                'RBBB': 'RBBB',\n",
    "                                                                'LBBB': 'LBBB',\n",
    "                                                                'LAFB': 'LAFB',\n",
    "                                                                'LAFB , LVH': 'LAFB',\n",
    "                                                                'Microvoltages , BF': 'BF',\n",
    "                                                                'Microvoltages , RBBB': 'RBBB',\n",
    "                                                                'Microvoltages , LAFB': 'LAFB', \n",
    "                                                                'LVH , BF': 'BF',\n",
    "                                                                'LVH , RBBB': 'RBBB',\n",
    "                                                                'LVH , LBBB': 'LBBB'\n",
    "                                                            }))\n",
    "if USE_REDUCED_LABELS:\n",
    "    CONDUCTION_DATA.loc[:, target_col] = CONDUCTION_DATA[target_col].map(Reduction_map)\n",
    "    \n",
    "CONDUCTION_DATA.to_parquet(os.path.join(data_path, fstring, 'CONDUCTION.parquet'))\n",
    "CONDUCTION_DATA = CONDUCTION_DATA.drop('Dataset', axis=1)\n",
    "\n",
    "json.dump(combine_kwargs, open(os.path.join(data_path, fstring, 'settings.json'), 'w'))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc77f778e5ba6dc3",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c063168d558da7a",
   "metadata": {},
   "source": [
    "splitter = RepeatedStratifiedKFold(n_splits=num_splits, n_repeats=num_repeats, random_state=7)\n",
    "X = CONDUCTION_DATA.iloc[:, :-1]\n",
    "Y = CONDUCTION_DATA.iloc[:,-1]\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lbe = LabelEncoder()\n",
    "Yenc = lbe.fit_transform(Y)\n",
    "lb.fit(Yenc)    \n",
    "ClassMap_CONDUCTION = {i:c for i,c in enumerate(lbe.classes_)}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d2e799addecd3dd",
   "metadata": {},
   "source": [
    "ClassMap_CONDUCTION"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4392a30a2cbe5aea",
   "metadata": {},
   "source": [
    "RES_LIST_CONDUCTION, RES_CONDUCTION_DF, RES_CONDUCTION_INDCS_DF = tree_utils.training_loop(X, Yenc, splitter, PipeDict,\n",
    "                                    use_class_weights=USE_CLASS_WEIGHT, \n",
    "                                    ClassMap=ClassMap_CONDUCTION,\n",
    "                                    num_splits=num_splits,num_repeats=num_repeats,\n",
    "                                    make_df=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb9808561967a6d3",
   "metadata": {},
   "source": [
    "### make roc and precision recall curves"
   ]
  },
  {
   "cell_type": "code",
   "id": "4ae73bcfe00c24c3",
   "metadata": {},
   "source": [
    "Y.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ec0e390ff9b9722",
   "metadata": {},
   "source": [
    "n_classes = len(lb.classes_)\n",
    "colors = ['blue', 'green', 'red', 'yellow', 'magenta', 'cyan', 'black']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11cf6bcf2eb9d9de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "59c90bef553b4566",
   "metadata": {},
   "source": [
    "PLOTS_CONDUCTION = tree_utils.make_plots(RES_LIST_CONDUCTION, lb,  n_classes, colors,\n",
    "                                         ClassMap_CONDUCTION,\n",
    "                                         output_map=os.path.join(data_path, fstring),\n",
    "                                         show_plot=False,\n",
    "                                         models = list(PipeDict.keys()),\n",
    "                                         plot_title=\"Heart Conduction\")\n",
    "\n",
    "perf_list = tree_utils.get_performance(RES_LIST_CONDUCTION,\n",
    "                                       threshold=1/n_classes, \n",
    "                                       ClassMap=ClassMap_CONDUCTION,\n",
    "                                       models = list(PipeDict.keys()),\n",
    "                                       binarizer=lb)\n",
    "\n",
    "PERF_CONDUCTION = pd.DataFrame(perf_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c727dfb89c2dfb2",
   "metadata": {},
   "source": [
    "PERF_CONDUCTION[['f1', 'precision', 'recall', 'specificity', 'model', 'Class']].groupby(['model', 'Class']).mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54d2906bf2a27141",
   "metadata": {},
   "source": [
    "tree_utils.net_benefit_curve_plot(RES_CONDUCTION_DF, true_col_prefix='Y_test',\n",
    "                                     pred_col_prefix='Y_pred',\n",
    "                                     output_path=os.path.join(data_path, fstring),\n",
    "                                     threshold_steps=20, \n",
    "                                     xlim=[0,0.5],\n",
    "                                     ylim=[-1,1],\n",
    "                                     plot_title=\"Heart Conduction\")\n",
    "\n",
    "tree_utils.calibration_curve_plot(RES_CONDUCTION_DF,\n",
    "                                   true_col_prefix='Y_test',\n",
    "                                   pred_col_prefix='Y_pred',\n",
    "                                   output_path=os.path.join(data_path, fstring),\n",
    "                                   n_bins=10,\n",
    "                                   plot_title=\"Heart Conduction\",\n",
    "                                   show_plot=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c2ad6a50ea3cb0be",
   "metadata": {},
   "source": [
    "RES_CONDUCTION_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS.parquet\"))\n",
    "RES_CONDUCTION_INDCS_DF.to_parquet(os.path.join(data_path, fstring, \"RESULTS_w_indices.parquet\"))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base_310)",
   "language": "python",
   "name": "python3_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
