{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:01.250229Z",
     "start_time": "2024-08-16T12:07:01.078116Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.abspath('.'),'..', 'src'))\n",
    "import tree_utils, ctree\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet, Lasso, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 362
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "We’d like to show in the tree-visualization the names for the outcomes as follows: \n",
    "-\t[X] In the conduction/muscle trees: SR should be ‘control’\n",
    "-\t[X] In the axis tree, ‘ normal axis’ should not be ‘ control’ , but just ‘ normal axis’ \n",
    "-\t[X] In the conduction tree, ‘BF’ should be ‘ BfB’ \n",
    "\n",
    "The trees that we will show and are thus the most important:\n",
    "1.\tConduction: Customized tree (no missing indicator features, with the morphology maps as we defined the 4 categories, with the customization of the QRS duration (of 110 and 120 ms as done before) \n",
    "2.\tAxis/muscle: semi-customized (only use the  features of the selection that we provided, no missing indicator features, with the morphology maps in 4 categories) \n",
    "\n",
    "We’ll compare in the ROC-curves, and the net benefit curves 3 models, so it would be great if we could have the net benefit curves with the following combinations of models (the ROC-curve figures, we can make ourselves once we have the results of the new trees).  \n",
    "-\tConduction: \n",
    "o\t1. xgb 2. lr 3. dt 4. Customized dt (the decision tree being the customized one as described in point 1 before)\n",
    "-\tAxis/muscle: \n",
    "o\t1.xgb 2. lr 3. Semi-customized dt (the decision tree being the semi-customized one as described in point 2 before)\n",
    "```\n"
   ],
   "id": "7f87dc36addd60da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:01.484417Z",
     "start_time": "2024-08-16T12:07:01.359775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "morphology_categories = {\n",
    "    'only positive, no notch/acc': ['R'], \n",
    "    'only negative, no notch/acc': ['S'],\n",
    "    'both positive and negative, no notch/acc': ['Q.R', 'Q.R.S', 'R.S'],\n",
    "    'only positive with notch/accent': [\n",
    "        'R.R_acc', 'R.Rn', 'R.Rn.R_acc', 'Rn.R', 'Rn.R.R_acc', 'Rn.R.Rn'\n",
    "    ],\n",
    "    'only negative with notch/accent': [\n",
    "        'S.Sn', 'Sn.S', 'Sn.S.Sn'\n",
    "    ],\n",
    "    'both positive and negative with notch/accent': [\n",
    "        'Q.R.R_acc', 'Q.R.R_acc.S', 'Q.R.Rn', 'Q.R.Rn.S', 'Q.R.S.R_acc',\n",
    "        'Q.R.S.R_acc.S_acc', 'Q.R.S.Sn', 'Q.Rn.R', 'Q.Rn.R.S', 'R.R_acc.S',\n",
    "        'R.R_acc.S.S_acc', 'R.Rn.S', 'R.S.R_acc', 'R.S.R_acc.S_acc', 'R.S.Rn',\n",
    "        'R.S.Rn.Sn', 'R.S.S_acc', 'R.S.Sn', 'R.Sn.S', 'R.Sn.S.R_acc',\n",
    "        'R.Sn.S.Sn', 'Rn.R.R_acc.S', 'Rn.R.Rn.S', 'Rn.R.S', 'Rn.R.S.R_acc',\n",
    "        'Rn.R.S.R_acc.S_acc', 'Rn.R.S.Rn'\n",
    "    ],\n",
    "    'none': ['none']\n",
    "}\n",
    "inv_morpho_map = {_v:k  for k,v in morphology_categories.items() for _v in v}\n"
   ],
   "id": "51ba2273109837cc",
   "outputs": [],
   "execution_count": 363
  },
  {
   "cell_type": "code",
   "id": "328fd92d0c0f1da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:01.593748Z",
     "start_time": "2024-08-16T12:07:01.484417Z"
    }
   },
   "source": "data_dir = r'J:\\Onderzoek\\21-763_rvanes_MiniECG-2-Data\\E_ResearchData\\2_ResearchData\\Parquet'",
   "outputs": [],
   "execution_count": 364
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:01.734426Z",
     "start_time": "2024-08-16T12:07:01.593748Z"
    }
   },
   "cell_type": "code",
   "source": "NameMap = pd.read_parquet(os.path.join(data_dir, '..', 'Name_toSimpleName.parquet'))",
   "id": "553efb423d7da36",
   "outputs": [],
   "execution_count": 365
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:01.875008Z",
     "start_time": "2024-08-16T12:07:01.734426Z"
    }
   },
   "cell_type": "code",
   "source": "NameMapDict = {k:v for k,v in zip(NameMap['Old_Name'].values, NameMap['New_Name'].values)}",
   "id": "d59dcb45d9b1223c",
   "outputs": [],
   "execution_count": 366
  },
  {
   "cell_type": "code",
   "id": "c6219ba685f490c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:01.984516Z",
     "start_time": "2024-08-16T12:07:01.875008Z"
    }
   },
   "source": [
    "MIN_MORPHO_PRESENCE = 0.15 # %\n",
    "MULTI_CLASS = False\n",
    "num_splits = 10\n",
    "num_repeats = 10\n",
    "MISSINGNESS_INDICATOR = False\n",
    "MORPHO_MAP = True\n",
    "\n",
    "MULTI_CLASS_STRING = \"_MultiClass\" if MULTI_CLASS else \"_BinaryClass\"\n",
    "MISSINGNESS_INDICATOR_STRING = \"_wMissing\" if MISSINGNESS_INDICATOR else \"\"\n",
    "MORPHO_MAP_STRING = \"_wMorphoMap\" if MORPHO_MAP else \"\"\n",
    "\n",
    "TARGET = \"muscle\" # axis, muscle, conduction\n",
    "rules_path = f'T://laupodteam/AIOS/Bram/notebooks/code_dev/miniECG_interpretation/TreeBuilder/assets/{TARGET}_tree.json'"
   ],
   "outputs": [],
   "execution_count": 367
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:02.124945Z",
     "start_time": "2024-08-16T12:07:01.984516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dir = os.path.join(r'J:\\Onderzoek\\21-763_rvanes_MiniECG-2-Data\\G_Output\\2_Data\\CustomTree', f'{TARGET}{MULTI_CLASS_STRING}')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "id": "19fa44efa6aff753",
   "outputs": [],
   "execution_count": 368
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:02.249948Z",
     "start_time": "2024-08-16T12:07:02.124945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if TARGET=='conduction':\n",
    "    rules_loader = ctree.LoadRules(rules_path, name_map=NameMapDict)\n",
    "    processed_rules = rules_loader.get_processed_rules()\n",
    "    \n",
    "    SplitColumn = rules_loader.fold_split_col\n",
    "    TargetCol = rules_loader.target_col\n",
    "    IgnoreCols = rules_loader.ignore_cols + [SplitColumn]\n",
    "    FeaturesToUse = rules_loader.features_to_use\n",
    "else:\n",
    "    rules_loader = None\n",
    "    processed_rules = None\n",
    "    rules_loader_dict = json.load(open(rules_path, 'r'))\n",
    "    \n",
    "    SplitColumn = rules_loader_dict['fold_split_col']\n",
    "    TargetCol = rules_loader_dict['target_col']\n",
    "    IgnoreCols = rules_loader_dict['ignore_cols'] + [SplitColumn]\n",
    "    FeaturesToUse = rules_loader_dict['features_to_use']"
   ],
   "id": "ec277f5dd147445a",
   "outputs": [],
   "execution_count": 369
  },
  {
   "cell_type": "code",
   "id": "51a537c95bdb9d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:02.437599Z",
     "start_time": "2024-08-16T12:07:02.249948Z"
    }
   },
   "source": [
    "DATA = pd.read_parquet(os.path.join(data_dir, f'DATA.parquet'))\n",
    "\n",
    "if len(FeaturesToUse)>0:\n",
    "    keep_columns = list(set(FeaturesToUse).difference(set(IgnoreCols)))\n",
    "else:\n",
    "    keep_columns = [c for c in DATA.columns if c not in IgnoreCols]\n",
    "    \n",
    "keep_columns = list(set(keep_columns+[TargetCol]))\n",
    "    \n",
    "DATA = DATA.loc[:, keep_columns]"
   ],
   "outputs": [],
   "execution_count": 370
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:02.578078Z",
     "start_time": "2024-08-16T12:07:02.437599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA.columns = [NameMapDict[c] for c in DATA.columns]\n",
    "morphology_columns = [c for c in DATA.columns if 'morphology' in c.lower()]\n",
    "lead_columns = [c for c in DATA.columns if ('lead' in c.lower()) & ('morphology' not in c.lower())]\n",
    "for c in morphology_columns:\n",
    "    DATA.loc[:, c] = DATA[c].apply(lambda x: x[0].strip(\",\").strip(\" \"))\n",
    "    DATA.loc[:, c] = DATA[c].apply(lambda x: x if x.strip()!=\"\" else \"none\")"
   ],
   "id": "8462f88b69787038",
   "outputs": [],
   "execution_count": 371
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:02.705160Z",
     "start_time": "2024-08-16T12:07:02.578078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if MORPHO_MAP:\n",
    "    for c in morphology_columns:\n",
    "        DATA.loc[:, c] = DATA[c].map(inv_morpho_map)\n",
    "        "
   ],
   "id": "8dc4908b9039d4ac",
   "outputs": [],
   "execution_count": 372
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:02.828128Z",
     "start_time": "2024-08-16T12:07:02.705160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = set()\n",
    "for lOl in [DATA[c].str.split(\".\").values for c in morphology_columns]:\n",
    "    for l in lOl:\n",
    "        for _s in l:\n",
    "            vocab.add(_s)\n",
    "Vocab = {k:v for k,v in enumerate(vocab)}"
   ],
   "id": "713ee896ce7264c8",
   "outputs": [],
   "execution_count": 373
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:02.968950Z",
     "start_time": "2024-08-16T12:07:02.828128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "OneHot = OneHotEncoder(drop=None, \n",
    "                       sparse_output=False, \n",
    "                       min_frequency=MIN_MORPHO_PRESENCE,\n",
    "                       handle_unknown='infrequent_if_exist')\n",
    "\n",
    "MorphologyOneHot = pd.DataFrame(data=OneHot.fit_transform(DATA[morphology_columns]), \n",
    "                            columns=OneHot.get_feature_names_out(morphology_columns),\n",
    "                            index=DATA.index)"
   ],
   "id": "efe3cc9646303824",
   "outputs": [],
   "execution_count": 374
  },
  {
   "cell_type": "code",
   "id": "88851f9624ac3ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.093765Z",
     "start_time": "2024-08-16T12:07:02.968950Z"
    }
   },
   "source": [
    "DATA = DATA.drop(morphology_columns, axis=1)\n",
    "DATA = pd.concat([DATA, MorphologyOneHot], axis=1)\n",
    "keep_columns = DATA.columns\n"
   ],
   "outputs": [],
   "execution_count": 375
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.203432Z",
     "start_time": "2024-08-16T12:07:03.093765Z"
    }
   },
   "cell_type": "code",
   "source": "#TODO: Make multiple DATA, X,Y for: AXIS, MUSCLE and CONDUCTION",
   "id": "2289fc3327ed1cfb",
   "outputs": [],
   "execution_count": 376
  },
  {
   "cell_type": "code",
   "id": "5c714dfc36621795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.312910Z",
     "start_time": "2024-08-16T12:07:03.203432Z"
    }
   },
   "source": [
    "if TARGET == 'conduction':\n",
    "    DATA = DATA.assign(Diagnosis=DATA.Diagnosis.map({\n",
    "                                                                    'SR': 'Control',\n",
    "                                                                    'BF': 'BfB',\n",
    "                                                                    'RBBB': 'RBBB',\n",
    "                                                                    'LBBB': 'LBBB',\n",
    "                                                                    'LAFB': 'LAFB',\n",
    "                                                                    'LAFB , LVH': 'LAFB',\n",
    "                                                                    'Microvoltages , BF': 'BfB',\n",
    "                                                                    'Microvoltages , RBBB': 'RBBB',\n",
    "                                                                    'Microvoltages , LAFB': 'LAFB', \n",
    "                                                                    'LVH , BF': 'BfB',\n",
    "                                                                    'LVH , RBBB': 'RBBB',\n",
    "                                                                    'LVH , LBBB': 'LBBB'\n",
    "                                                                }))\n",
    "    Reduction_map = {'BfB': 'Abnormal', \n",
    "                     'LBBB': 'Abnormal', \n",
    "                     'RBBB': 'Abnormal',\n",
    "                     'LAFB': 'Abnormal',\n",
    "                     'Control': 'Control'}\n",
    "elif TARGET == 'axis':\n",
    "    if MULTI_CLASS:\n",
    "        target_inclusion = ['Left', 'Normal', 'Right']\n",
    "    else:\n",
    "        target_inclusion = ['Left', 'Normal', 'Right', 'Extreme']\n",
    "    DATA = DATA.loc[DATA['Heart Axis Diagnosis'].isin(target_inclusion)]    \n",
    "    Reduction_map = {'Left': 'Abnormal', \n",
    "                     'Right': 'Abnormal',\n",
    "                     'Extreme': 'Abnormal',\n",
    "                     'Normal': 'Normal'}   \n",
    "elif TARGET == 'muscle':\n",
    "    DATA = DATA.assign(Diagnosis=DATA.Diagnosis.map({\n",
    "                                                            'SR': 'Control',\n",
    "                                                            'Microvoltages': 'Microvoltages',\n",
    "                                                            'LVH': 'LVH',\n",
    "                                                            'LAFB , LVH': 'LVH',\n",
    "                                                            'Microvoltages , BF': 'Microvoltages',\n",
    "                                                            'Microvoltages , RBBB': 'Microvoltages',\n",
    "                                                            'Microvoltages , LAFB': 'Microvoltages',\n",
    "                                                            'LVH , BF': 'LVH',\n",
    "                                                            'LVH , RBBB': 'LVH',\n",
    "                                                            'LVH , LBBB': 'LVH'\n",
    "                                                        }))\n",
    "    target_inclusion = ['Control','LVH','Microvoltages']\n",
    "    DATA = DATA.loc[DATA['Diagnosis'].isin(target_inclusion)]    \n",
    "\n",
    "    Reduction_map = {'Microvoltages': 'Abnormal', \n",
    "                     'LVH': 'Abnormal',\n",
    "                     'Control': 'Control'}\n",
    "else:\n",
    "    raise ValueError(f'Unknown target {TARGET}')\n"
   ],
   "outputs": [],
   "execution_count": 377
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.422071Z",
     "start_time": "2024-08-16T12:07:03.313330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if MULTI_CLASS==False:\n",
    "    DATA.loc[:, TargetCol] = DATA[TargetCol].map(Reduction_map)\n",
    "DATA = DATA.dropna(subset=[TargetCol])"
   ],
   "id": "df88667be8a69e6c",
   "outputs": [],
   "execution_count": 378
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.531261Z",
     "start_time": "2024-08-16T12:07:03.422071Z"
    }
   },
   "cell_type": "code",
   "source": "Infreq_cat_dict = {morphology_columns[k]:list(inf_cats) for k, inf_cats in enumerate(OneHot.infrequent_categories_)}",
   "id": "ddc59f592300e9f0",
   "outputs": [],
   "execution_count": 379
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.672141Z",
     "start_time": "2024-08-16T12:07:03.531261Z"
    }
   },
   "cell_type": "code",
   "source": "json.dump(Infreq_cat_dict, open(os.path.join(output_dir, 'infrequent_categories_map.json'), 'w'))",
   "id": "e647cddbf1921ef2",
   "outputs": [],
   "execution_count": 380
  },
  {
   "cell_type": "markdown",
   "id": "63e34320264c5225",
   "metadata": {},
   "source": [
    "# Make tree"
   ]
  },
  {
   "cell_type": "code",
   "id": "705c65e4096a8ae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.781551Z",
     "start_time": "2024-08-16T12:07:03.672141Z"
    }
   },
   "source": [
    "TreeKwargs = {\n",
    "    'criterion':'gini', \n",
    "    'splitter':'best', \n",
    "    'max_depth':5, \n",
    "    'min_samples_split':10, \n",
    "    'min_samples_leaf': 5, \n",
    "    'min_weight_fraction_leaf':0.05, \n",
    "    'max_features':None, \n",
    "    'random_state':7, \n",
    "    'max_leaf_nodes':50,\n",
    "    'class_weight': 'balanced'\n",
    "}\n",
    "xgboost_kwargs = {\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 6,\n",
    "    'max_leaves': 50,\n",
    "    'learning_rate': 2e-3,\n",
    "    'gamma': 0.4,\n",
    "    'subsample': 0.55,\n",
    "    'colsample_bytree':0.85,\n",
    "    'reg_alpha': 0.005\n",
    "}\n",
    "logistic_kwargs = {\n",
    "    'penalty': 'elasticnet', \n",
    "    'solver': 'saga', \n",
    "    'dual': False, \n",
    "    'tol': 0.0001, \n",
    "    'C':1.0, \n",
    "    'fit_intercept': True, \n",
    "    'intercept_scaling':1, \n",
    "    'class_weight':None, \n",
    "    'random_state':7,     \n",
    "    'max_iter':3000, \n",
    "    'verbose': 0, \n",
    "    'warm_start': False, \n",
    "    'n_jobs':-1, \n",
    "    'l1_ratio':0.5\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 381
  },
  {
   "cell_type": "code",
   "id": "17a47f3113df9286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:03.890806Z",
     "start_time": "2024-08-16T12:07:03.781551Z"
    }
   },
   "source": [
    "Splitter = RepeatedStratifiedKFold(n_splits=num_splits, \n",
    "                                   n_repeats=num_repeats, \n",
    "                                   random_state=7)"
   ],
   "outputs": [],
   "execution_count": 382
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:04.015571Z",
     "start_time": "2024-08-16T12:07:03.890806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = DATA.loc[:,[c for c in keep_columns if c!=TargetCol]]\n",
    "Y = DATA[TargetCol]"
   ],
   "id": "a68d125a4d2c9de5",
   "outputs": [],
   "execution_count": 383
  },
  {
   "cell_type": "code",
   "id": "7e0fe0a87ee2e48a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:04.125262Z",
     "start_time": "2024-08-16T12:07:04.015571Z"
    }
   },
   "source": [
    "lb = LabelBinarizer()\n",
    "lbe = LabelEncoder()\n",
    "lbe.fit(Y)\n",
    "TargetMap = {k:v for k,v in enumerate(lbe.classes_)}"
   ],
   "outputs": [],
   "execution_count": 384
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:04.234542Z",
     "start_time": "2024-08-16T12:07:04.125262Z"
    }
   },
   "cell_type": "code",
   "source": "TargetMap.values()",
   "id": "c944ee82a01ff1fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Abnormal', 'Control'])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 385
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:04.699221Z",
     "start_time": "2024-08-16T12:07:04.234542Z"
    }
   },
   "cell_type": "code",
   "source": "X.to_parquet(os.path.join(output_dir, f'data{MULTI_CLASS_STRING}{MISSINGNESS_INDICATOR_STRING}{MORPHO_MAP_STRING}.parquet'))",
   "id": "50139353f8bb4626",
   "outputs": [],
   "execution_count": 386
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:54.218377Z",
     "start_time": "2024-08-16T12:07:04.699221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_list = []\n",
    "for i, (train_index, test_index) in tqdm.tqdm(enumerate(Splitter.split(X, Y)),\n",
    "                                              total=num_splits * num_repeats):\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    \n",
    "    y_train_encoded = lbe.transform(Y_train)\n",
    "    y_test_encoded = lbe.transform(Y_test)\n",
    "        \n",
    "    #Imputer = IterativeImputer(Lasso(), \n",
    "    #                           add_indicator=MISSINGNESS_INDICATOR, \n",
    "    #                           max_iter=5_000, verbose=0)\n",
    "    Imputer = KNNImputer(add_indicator=MISSINGNESS_INDICATOR, n_neighbors=10, weights='distance')\n",
    "    \n",
    "    Imputer.fit(X_train)\n",
    "    \n",
    "    X_train_imputed = Imputer.transform(X_train)\n",
    "    X_test_imputed = Imputer.transform(X_test)\n",
    "    \n",
    "    X_train_imputed = pd.DataFrame(data=X_train_imputed,\n",
    "                                   columns=Imputer.get_feature_names_out())\n",
    "    \n",
    "    X_test_imputed = pd.DataFrame(data=X_test_imputed,\n",
    "                                   columns=Imputer.get_feature_names_out())\n",
    "    \n",
    "    clf = ctree.CustomDecisionTreeV2(custom_rules=processed_rules,\n",
    "                             prune_threshold=None,\n",
    "                             Tree_kwargs=TreeKwargs,\n",
    "                             TargetMap = TargetMap, \n",
    "                             tot_max_depth=5)\n",
    "    if processed_rules is not None:\n",
    "        #print(\"Training custom tree...\")\n",
    "        clf.fit(X_train_imputed, y_train_encoded)\n",
    "        enriched_rules = clf.get_enriched_rules()\n",
    "        final_tree = clf.get_custom_rules_model()\n",
    "        \n",
    "        #############################\n",
    "        ## Writing out the tree #####\n",
    "        #############################\n",
    "        \n",
    "        if processed_rules is not None:\n",
    "            json.dump(final_tree, \n",
    "                      open(os.path.join(output_dir, f\"tree_Fold{Fold}_{Repeat}{MULTI_CLASS_STRING}{MISSINGNESS_INDICATOR_STRING}{MORPHO_MAP_STRING}.json\"), mode='w'))\n",
    "            ctree.update_html(tree=final_tree, \n",
    "                              html_path=\"../src/treeTemplate.html\", \n",
    "                              output_path=os.path.join(output_dir, f\"tree_Fold{Fold}_{Repeat}{MULTI_CLASS_STRING}{MISSINGNESS_INDICATOR_STRING}{MORPHO_MAP_STRING}.html\"))\n",
    "        cust_probas_train = clf.predict_proba(X_train_imputed)\n",
    "        cust_probas_test = clf.predict_proba(X_test_imputed)\n",
    "\n",
    "\n",
    "    clf_base = DecisionTreeClassifier(**TreeKwargs)\n",
    "    clf_xgb = XGBClassifier(**xgboost_kwargs)\n",
    "    clf_logistic = LogisticRegression(**logistic_kwargs)\n",
    "    \n",
    "    #print(\"Training classifiers...\")\n",
    "    #print(\"Training standard decision tree...\")\n",
    "    clf_base.fit(X_train_imputed, y_train_encoded)\n",
    "    #print(\"Training xgboost...\")\n",
    "    clf_xgb.fit(X_train_imputed, y_train_encoded)\n",
    "    #print(\"Training logistic regression...\")\n",
    "    clf_logistic.fit(X_train_imputed, y_train_encoded)\n",
    "    \n",
    "    Fold = i % num_splits\n",
    "    Repeat = i // num_splits\n",
    "    \n",
    "    #############################\n",
    "    ## Writing out the tree #####\n",
    "    #############################\n",
    "    \n",
    "    sklearn_tree = clf.load_from_sklearn_tree(clf_base, X_train_imputed, y_train_encoded)\n",
    "    final_tree_sklearn = sklearn_tree.get_custom_rules_model()\n",
    "    json.dump(final_tree_sklearn, \n",
    "              open(os.path.join(output_dir, f\"sklearn_tree_Fold{Fold}_{Repeat}{MULTI_CLASS_STRING}{MISSINGNESS_INDICATOR_STRING}{MORPHO_MAP_STRING}.json\"), mode='w'))\n",
    "    ctree.update_html(tree=final_tree_sklearn, \n",
    "                     html_path=\"../src/treeTemplate.html\", \n",
    "                     output_path=os.path.join(output_dir, f\"sklearn_tree_Fold{Fold}_{Repeat}{MULTI_CLASS_STRING}{MISSINGNESS_INDICATOR_STRING}{MORPHO_MAP_STRING}.html\"))\n",
    "    #############################\n",
    "    #############################\n",
    "    #############################    \n",
    "\n",
    "    \n",
    "    base_probas_train = clf_base.predict_proba(X_train_imputed)\n",
    "    base_probas_test = clf_base.predict_proba(X_test_imputed)\n",
    "    \n",
    "    xgb_probas_train = clf_xgb.predict_proba(X_train_imputed)\n",
    "    xgb_probas_test = clf_xgb.predict_proba(X_test_imputed)\n",
    "    \n",
    "    logistic_probas_train = clf_logistic.predict_proba(X_train_imputed)\n",
    "    logistic_probas_test = clf_logistic.predict_proba(X_test_imputed)\n",
    "    \n",
    "    result_df['indices'] = np.hstack([train_index, test_index])\n",
    "    result_df['Fold'] = Fold\n",
    "    result_df['Repeat'] = Repeat\n",
    "    result_df['Y_true'] = np.hstack([Y_train.values, Y_test.values])\n",
    "    result_df[[f'Y_pred_normalDT_{cname}' for cname in TargetMap.values()]] = np.vstack([base_probas_train, base_probas_test])\n",
    "    if processed_rules is not None:\n",
    "        result_df[[f'Y_pred_customDT_{cname}' for cname in TargetMap.values()]] = np.vstack([cust_probas_train, cust_probas_test])\n",
    "    result_df[[f'Y_pred_XGB_{cname}' for cname in TargetMap.values()]] = np.vstack([xgb_probas_train, xgb_probas_test])\n",
    "    result_df[[f'Y_pred_LR_{cname}' for cname in TargetMap.values()]] = np.vstack([logistic_probas_train, logistic_probas_test])    \n",
    "    result_df['Dataset'] = ['train' for _ in train_index]+['test' for _ in test_index]\n",
    "    \n",
    "    results_list.append(result_df)\n",
    "    \n"
   ],
   "id": "72e244d313d5c294",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "execution_count": 387
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:58.953624Z",
     "start_time": "2024-08-16T12:07:54.218377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Final_results = pd.concat(results_list, axis=0, ignore_index=True)\n",
    "Fina_results = Final_results.reset_index(drop=True)\n",
    "\n",
    "classes = set([c.split(\"_\")[-1] for c in Final_results.columns if 'pred' in c])\n",
    "\n",
    "for _class in classes:\n",
    "    Final_results[f'Y_true_{_class}'] = (Final_results['Y_true'] == _class).astype(int)\n",
    "\n",
    "Final_results.to_csv(\n",
    "    os.path.join(output_dir, f\"results{MULTI_CLASS_STRING}{MISSINGNESS_INDICATOR_STRING}{MORPHO_MAP_STRING}.csv\"),\n",
    "    index=False, sep=\";\")\n",
    "\n",
    "Final_results.to_parquet(\n",
    "    os.path.join(output_dir, f\"results{MULTI_CLASS_STRING}{MISSINGNESS_INDICATOR_STRING}{MORPHO_MAP_STRING}.parquet\"))"
   ],
   "id": "6bb23977f46fe04d",
   "outputs": [],
   "execution_count": 388
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T12:07:59.124600Z",
     "start_time": "2024-08-16T12:07:58.953624Z"
    }
   },
   "cell_type": "code",
   "source": "Final_results",
   "id": "d4546e88efb16d80",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        indices  Fold  Repeat    Y_true  Y_pred_normalDT_Abnormal  \\\n",
       "0             0     0       0   Control                  0.123403   \n",
       "1             1     0       0   Control                  0.310226   \n",
       "2             2     0       0  Abnormal                  0.806630   \n",
       "3             3     0       0  Abnormal                  0.981658   \n",
       "4             4     0       0   Control                  0.123403   \n",
       "...         ...   ...     ...       ...                       ...   \n",
       "106195      965     9       9  Abnormal                  0.571594   \n",
       "106196      969     9       9   Control                  0.535698   \n",
       "106197      977     9       9   Control                  0.099405   \n",
       "106198      999     9       9  Abnormal                  0.408234   \n",
       "106199     1040     9       9   Control                  0.535698   \n",
       "\n",
       "        Y_pred_normalDT_Control  Y_pred_XGB_Abnormal  Y_pred_XGB_Control  \\\n",
       "0                      0.876597             0.310513            0.689487   \n",
       "1                      0.689774             0.353006            0.646994   \n",
       "2                      0.193370             0.495648            0.504352   \n",
       "3                      0.018342             0.504255            0.495745   \n",
       "4                      0.876597             0.337997            0.662003   \n",
       "...                         ...                  ...                 ...   \n",
       "106195                 0.428406             0.391041            0.608959   \n",
       "106196                 0.464302             0.342372            0.657628   \n",
       "106197                 0.900595             0.316385            0.683615   \n",
       "106198                 0.591766             0.400301            0.599699   \n",
       "106199                 0.464302             0.406558            0.593442   \n",
       "\n",
       "        Y_pred_LR_Abnormal  Y_pred_LR_Control Dataset  Y_true_Abnormal  \\\n",
       "0                 0.225047           0.774953   train                0   \n",
       "1                 0.201014           0.798986   train                0   \n",
       "2                 0.753306           0.246694   train                1   \n",
       "3                 0.854142           0.145858   train                1   \n",
       "4                 0.193209           0.806791   train                0   \n",
       "...                    ...                ...     ...              ...   \n",
       "106195            0.321081           0.678919    test                1   \n",
       "106196            0.229781           0.770219    test                0   \n",
       "106197            0.095205           0.904795    test                0   \n",
       "106198            0.386542           0.613458    test                1   \n",
       "106199            0.067645           0.932355    test                0   \n",
       "\n",
       "        Y_true_Control  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    1  \n",
       "...                ...  \n",
       "106195               0  \n",
       "106196               1  \n",
       "106197               1  \n",
       "106198               0  \n",
       "106199               1  \n",
       "\n",
       "[106200 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Y_true</th>\n",
       "      <th>Y_pred_normalDT_Abnormal</th>\n",
       "      <th>Y_pred_normalDT_Control</th>\n",
       "      <th>Y_pred_XGB_Abnormal</th>\n",
       "      <th>Y_pred_XGB_Control</th>\n",
       "      <th>Y_pred_LR_Abnormal</th>\n",
       "      <th>Y_pred_LR_Control</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Y_true_Abnormal</th>\n",
       "      <th>Y_true_Control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.123403</td>\n",
       "      <td>0.876597</td>\n",
       "      <td>0.310513</td>\n",
       "      <td>0.689487</td>\n",
       "      <td>0.225047</td>\n",
       "      <td>0.774953</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.310226</td>\n",
       "      <td>0.689774</td>\n",
       "      <td>0.353006</td>\n",
       "      <td>0.646994</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.798986</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.193370</td>\n",
       "      <td>0.495648</td>\n",
       "      <td>0.504352</td>\n",
       "      <td>0.753306</td>\n",
       "      <td>0.246694</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>0.981658</td>\n",
       "      <td>0.018342</td>\n",
       "      <td>0.504255</td>\n",
       "      <td>0.495745</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.145858</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.123403</td>\n",
       "      <td>0.876597</td>\n",
       "      <td>0.337997</td>\n",
       "      <td>0.662003</td>\n",
       "      <td>0.193209</td>\n",
       "      <td>0.806791</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106195</th>\n",
       "      <td>965</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>0.571594</td>\n",
       "      <td>0.428406</td>\n",
       "      <td>0.391041</td>\n",
       "      <td>0.608959</td>\n",
       "      <td>0.321081</td>\n",
       "      <td>0.678919</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106196</th>\n",
       "      <td>969</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.535698</td>\n",
       "      <td>0.464302</td>\n",
       "      <td>0.342372</td>\n",
       "      <td>0.657628</td>\n",
       "      <td>0.229781</td>\n",
       "      <td>0.770219</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106197</th>\n",
       "      <td>977</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.099405</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.316385</td>\n",
       "      <td>0.683615</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>0.904795</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106198</th>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>0.408234</td>\n",
       "      <td>0.591766</td>\n",
       "      <td>0.400301</td>\n",
       "      <td>0.599699</td>\n",
       "      <td>0.386542</td>\n",
       "      <td>0.613458</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106199</th>\n",
       "      <td>1040</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.535698</td>\n",
       "      <td>0.464302</td>\n",
       "      <td>0.406558</td>\n",
       "      <td>0.593442</td>\n",
       "      <td>0.067645</td>\n",
       "      <td>0.932355</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106200 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 389
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
